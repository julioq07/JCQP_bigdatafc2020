{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 0 \n",
    "## CRUD de HDFS con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentación que utilicé la saqué de las siguientes fuentes:\n",
    "- https://hdfscli.readthedocs.io/en/latest/api.html\n",
    "- https://docs.python.org/3/library/os.html \n",
    "- https://hdfscli.readthedocs.io/en/latest/quickstart.html\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient\n",
    "import json as js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexion(url):\n",
    "    \"\"\"\n",
    "    Esta función logra la conexión con hfds\n",
    "    \n",
    "    La url debe ser un string no nulo del host\n",
    "    \"\"\"\n",
    "    url = 'http://localhost:9870'\n",
    "    try:\n",
    "        client = InsecureClient(url) \n",
    "        return client\n",
    "    except:\n",
    "        print(\"¡Ocurrió un error! Favor de verificar la url del host\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_directorio(client, hdfs_path):\n",
    "    \"\"\"\n",
    "    Esta función crea un directorio en hdfs con la ruta dada\n",
    "    \n",
    "    Usamos el método 'makedirs()' donde el parámetro es un string de la ruta del directorio que queremos crear en HDFS\n",
    "    \"\"\"'\n",
    "    try:\n",
    "        create_path = client.makedirs(hdfs_path)\n",
    "        print(\"¡Felicidades! Se ha creado el directorio \" + hdfs_path)\n",
    "        return create_path\n",
    "    except:\n",
    "        print(\"Ocurrió un problema. Por favor verifica la ruta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_archivo(client, hdfs_path, local_path):\n",
    "    \"\"\"\n",
    "    Esta función carga un archivo o directorio de la ruta local hacia un directorio en HDFS\n",
    "\n",
    "    Usamos el método 'upload()' donde debemos de indicaerle en el primer parámetro un str con la ruta del directorio a donde queremos cargar el archivo/directorio en HDFS y en el segundo parámetro un string con la ruta del archivo/directorio que queremos cargar; la cual se encuentra en la ruta local (i.e. la que no está en HDFS)\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        load_file = client.upload(hdfs_path, local_path)\n",
    "        return(load_file)\n",
    "        print(\"Ahora ya se ha cargado el archivo con ruta: \" + local_path)\n",
    "    except:\n",
    "        print(\"Ocurrió un error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_directorio(client, hdfs_path):\n",
    "    \"\"\"\n",
    "    Esta función toma el directorio en la ruta dada y lista sus archivos\n",
    "    \n",
    "    Primero usamos el método 'listdir()' el cual recibe como parámetro un str con la ruta del directorio al cual queremos listar ubicado en HDFS. Éste nos regresa una lista con los archivos/directorios pertenecientes en tipo str. Luego, hacemos un ciclo para recorrer estos elementos y determinar cuáles de ellos son archivos y cuales directorios. Para esto usamos el método 'path.isfile()' el cual tiene como parámetro un str de la ruta de los elementos del directorio que queremos listar. Para darle ese str, tenemos que contruirlo a partir de los elementos de la iteración, y para eso usamos el método 'path.join( , )' que recibe como primer parámetro la ruta del directorio que queremos listar y como segundo el str del elemento en la lista de dicho directorio; para devolvernos un str que contiene la ruta del elemento del directorio a listar que queremos determinar. Para determinar si es o no un tipo archivo, usamos el 'if - print'. Al final tendremos la impresión de todos los elementos tipo archivo del directorio a interes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tomamos el directorio de la ruta y listamos sus elementos como tipo str \n",
    "        # Para cada elemento en la lista del directorio\n",
    "        # Nos fijamos en aquellos que sean archivos solamente mediante el método client.path.join(ruta_directorio, elemento_del_directorio). Éste contruye la ruta de los elementos que están en el directorio. P.ej. clase={a.txt,a.py,sub_dir}\n",
    "        # client.path.join(ruta_dir=/home/julio/desktop/clase, elemento=sub_dir)=/home/julio/desktop/clase/subdir -> .isfile(directorio)\n",
    "        # Y los imprimimos\n",
    "        print('A continuación se lista los archivos del directorio en HDFS con ruta: hdfs_path' + hdfs_path)\n",
    "        for element in client.listdir(hdfs_path):  \n",
    "            if client.path.isfile(client.path.join(hdfs_path, element)):\n",
    "                print(element)\n",
    "    except:\n",
    "        print(\"Ocurrió un problema. Por favor verifica la ruta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_HDFS(client, file_path):\n",
    "    \"\"\"\n",
    "    Esta función nos permite la lectura del archivo dado\n",
    "\n",
    "    Usando el método 'open()' abrimos el archivo deseado y lo guardamos en la variable 'open_file'. Para esto debemos alimentar a éste método con la ruta tipo str del archivo en cuestión. Luego, con el método 'read()' leemos la variable donde está guardado el archivo y lo guardamos en la variable 'read'. Una vez guardado, imprimimos dicha variable y finalmente cerramos el archivo con el método 'close()'.\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        print('Ahora leemos el archivo en HDFS con ruta: ' + file_path)\n",
    "        open_file = client.open(file_path)\n",
    "        read = client.read(open_file)\n",
    "        print(read)\n",
    "        client.close(open_file)\n",
    "    except:\n",
    "        print(\"Ocurrió un problema. No sé cuál...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_directorio(client, hdfs_path):\n",
    "    \"\"\"\n",
    "    Esta función elimina un directorio\n",
    "    \n",
    "    Usamos el método 'remove()' para eliminar el directorio dada la ruta como tipo str\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #Eliminamos la ruta 'path_hdfs' del cliente 'client'\n",
    "        client.remove(hdfs_path)\n",
    "        print('Se ha eliminado el directorio en HDFS con ruta: ' + hdfs_path)\n",
    "    except OSError:\n",
    "        print(\"Ocurrió un problema. Por favor verifica la ruta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'conexion' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-281d1df83c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0meliminar_directorio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdfs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-281d1df83c5a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/julio/docker-hadoop/prueba_tarea_hdfs/prueba_tarea_hdfs/prueba_tarea_hdfs.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconexion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcrear_directorio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdfs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conexion' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Para llevar a cabo el CRUD necesitamos definir la ruta para conectarnos con HDFS ('url'), la ruta en HDFS del directorio que queremos crear ('hdfs_path'), la ruta del archivo ubicado fuera de HDFS que queremos cargar al directorio creado ('local_path') y la ruta del archivo que hemos cargado y que queremos leer ubicado en HDFS ('file_path')\n",
    "\n",
    "    Al final invocamos a nuestras funciones para realizar el CRUD\n",
    "\n",
    "    NOTA IMPORTANTE: Las rutas que he puesto relacionadas a la ubicación de HDFS (hdfs y file) no son las correctas debido a que nunca pude instalar correctamente Honrtonswork-Sandbox en mi máquina con Docker. Aún así, teóricamente, tengo claro que esas rutas deben vivir en los repositorios que haya creado con Docker \n",
    "    \"\"\"\n",
    "\n",
    "    url = 'http://localhost:9870'\n",
    "    \n",
    "    hdfs_path  = '/home/julio/docker-hadoop/prueba_tarea_hdfs '\n",
    "\n",
    "    local_path = '/home/julio/Desktop/Clase_Jimmy/BigData20202/Tarea0/prueba_tarea_hdfs.json'\n",
    "\n",
    "    file_path = '/home/julio/docker-hadoop/prueba_tarea_hdfs/prueba_tarea_hdfs/prueba_tarea_hdfs.json' \n",
    "\n",
    "    client = conexion(url)\n",
    "\n",
    "    crear_directorio(client, hdfs_path)\n",
    "\n",
    "    cargar_archivo(client, hdfs_path, local_path)\n",
    "\n",
    "    lista_directorio(client, hdfs_path)\n",
    "\n",
    "    lectura_HDFS(client, file_path)\n",
    "\n",
    "    eliminar_directorio(client, hdfs_path)\n",
    "\n",
    "main()"
   ]
  }
 ]
}